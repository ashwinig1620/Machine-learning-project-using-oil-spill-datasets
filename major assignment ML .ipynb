{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>...</th>\n",
       "      <th>f_41</th>\n",
       "      <th>f_42</th>\n",
       "      <th>f_43</th>\n",
       "      <th>f_44</th>\n",
       "      <th>f_45</th>\n",
       "      <th>f_46</th>\n",
       "      <th>f_47</th>\n",
       "      <th>f_48</th>\n",
       "      <th>f_49</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>200</td>\n",
       "      <td>12</td>\n",
       "      <td>92.42</td>\n",
       "      <td>364.42</td>\n",
       "      <td>135</td>\n",
       "      <td>97200</td>\n",
       "      <td>59.42</td>\n",
       "      <td>10.34</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>381.84</td>\n",
       "      <td>254.56</td>\n",
       "      <td>84.85</td>\n",
       "      <td>146.97</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2593.50</td>\n",
       "      <td>65.85</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>201</td>\n",
       "      <td>11</td>\n",
       "      <td>98.82</td>\n",
       "      <td>248.64</td>\n",
       "      <td>159</td>\n",
       "      <td>89100</td>\n",
       "      <td>59.64</td>\n",
       "      <td>10.18</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>284.60</td>\n",
       "      <td>180.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>51.96</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>4361.25</td>\n",
       "      <td>65.70</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>202</td>\n",
       "      <td>14</td>\n",
       "      <td>25.14</td>\n",
       "      <td>428.86</td>\n",
       "      <td>24</td>\n",
       "      <td>113400</td>\n",
       "      <td>60.14</td>\n",
       "      <td>17.94</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0</td>\n",
       "      <td>2153.05</td>\n",
       "      <td>65.91</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>203</td>\n",
       "      <td>10</td>\n",
       "      <td>96.00</td>\n",
       "      <td>451.30</td>\n",
       "      <td>68</td>\n",
       "      <td>81000</td>\n",
       "      <td>59.90</td>\n",
       "      <td>15.01</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>73.48</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2421.43</td>\n",
       "      <td>65.97</td>\n",
       "      <td>6.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>204</td>\n",
       "      <td>11</td>\n",
       "      <td>7.73</td>\n",
       "      <td>235.73</td>\n",
       "      <td>135</td>\n",
       "      <td>89100</td>\n",
       "      <td>61.82</td>\n",
       "      <td>12.24</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>254.56</td>\n",
       "      <td>254.56</td>\n",
       "      <td>127.28</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3782.68</td>\n",
       "      <td>65.65</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     f_1    f_2      f_3     f_4  f_5       f_6    f_7    f_8      f_9  f_10   \n",
       "0      1   2558  1506.09  456.63   90   6395000  40.88   7.89  29780.0  0.19  \\\n",
       "1      2  22325    79.11  841.03  180  55812500  51.11   1.21  61900.0  0.02   \n",
       "2      3    115  1449.85  608.43   88    287500  40.42   7.34   3340.0  0.18   \n",
       "3      4   1201  1562.53  295.65   66   3002500  42.40   7.97  18030.0  0.19   \n",
       "4      5    312   950.27  440.86   37    780000  41.43   7.03   3350.0  0.17   \n",
       "..   ...    ...      ...     ...  ...       ...    ...    ...      ...   ...   \n",
       "932  200     12    92.42  364.42  135     97200  59.42  10.34    884.0  0.17   \n",
       "933  201     11    98.82  248.64  159     89100  59.64  10.18    831.0  0.17   \n",
       "934  202     14    25.14  428.86   24    113400  60.14  17.94    847.0  0.30   \n",
       "935  203     10    96.00  451.30   68     81000  59.90  15.01    831.0  0.25   \n",
       "936  204     11     7.73  235.73  135     89100  61.82  12.24    831.0  0.20   \n",
       "\n",
       "     ...     f_41      f_42     f_43     f_44   f_45  f_46      f_47   f_48   \n",
       "0    ...  2850.00   1000.00   763.16   135.46   3.73     0  33243.19  65.74  \\\n",
       "1    ...  5750.00  11500.00  9593.48  1648.80   0.60     0  51572.04  65.73   \n",
       "2    ...  1400.00    250.00   150.00    45.13   9.33     1  31692.84  65.81   \n",
       "3    ...  6041.52    761.58   453.21   144.97  13.33     1  37696.21  65.67   \n",
       "4    ...  1320.04    710.63   512.54   109.16   2.58     0  29038.17  65.66   \n",
       "..   ...      ...       ...      ...      ...    ...   ...       ...    ...   \n",
       "932  ...   381.84    254.56    84.85   146.97   4.50     0   2593.50  65.85   \n",
       "933  ...   284.60    180.00   150.00    51.96   1.90     0   4361.25  65.70   \n",
       "934  ...   402.49    180.00   180.00     0.00   2.24     0   2153.05  65.91   \n",
       "935  ...   402.49    180.00    90.00    73.48   4.47     0   2421.43  65.97   \n",
       "936  ...   254.56    254.56   127.28   180.00   2.00     0   3782.68  65.65   \n",
       "\n",
       "     f_49  target  \n",
       "0    7.95       1  \n",
       "1    6.26       0  \n",
       "2    7.84       1  \n",
       "3    8.07       1  \n",
       "4    7.35       0  \n",
       "..    ...     ...  \n",
       "932  6.39       0  \n",
       "933  6.53       0  \n",
       "934  6.12       0  \n",
       "935  6.32       0  \n",
       "936  6.26       0  \n",
       "\n",
       "[937 rows x 50 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'G:\\My Drive\\oil_spill.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>...</th>\n",
       "      <th>f_41</th>\n",
       "      <th>f_42</th>\n",
       "      <th>f_43</th>\n",
       "      <th>f_44</th>\n",
       "      <th>f_45</th>\n",
       "      <th>f_46</th>\n",
       "      <th>f_47</th>\n",
       "      <th>f_48</th>\n",
       "      <th>f_49</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>9.370000e+02</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>81.588047</td>\n",
       "      <td>332.842049</td>\n",
       "      <td>698.707086</td>\n",
       "      <td>870.992209</td>\n",
       "      <td>84.121665</td>\n",
       "      <td>7.696964e+05</td>\n",
       "      <td>43.242721</td>\n",
       "      <td>9.127887</td>\n",
       "      <td>3940.712914</td>\n",
       "      <td>0.221003</td>\n",
       "      <td>...</td>\n",
       "      <td>933.928677</td>\n",
       "      <td>427.565582</td>\n",
       "      <td>255.435902</td>\n",
       "      <td>106.112519</td>\n",
       "      <td>5.014002</td>\n",
       "      <td>0.128068</td>\n",
       "      <td>7985.718004</td>\n",
       "      <td>61.694386</td>\n",
       "      <td>8.119723</td>\n",
       "      <td>0.043757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>64.976730</td>\n",
       "      <td>1931.938570</td>\n",
       "      <td>599.965577</td>\n",
       "      <td>522.799325</td>\n",
       "      <td>45.361771</td>\n",
       "      <td>3.831151e+06</td>\n",
       "      <td>12.718404</td>\n",
       "      <td>3.588878</td>\n",
       "      <td>8167.427625</td>\n",
       "      <td>0.090316</td>\n",
       "      <td>...</td>\n",
       "      <td>1001.681331</td>\n",
       "      <td>715.391648</td>\n",
       "      <td>534.306194</td>\n",
       "      <td>135.617708</td>\n",
       "      <td>5.029151</td>\n",
       "      <td>0.334344</td>\n",
       "      <td>6854.504915</td>\n",
       "      <td>10.412807</td>\n",
       "      <td>2.908895</td>\n",
       "      <td>0.204662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.031200e+04</td>\n",
       "      <td>21.240000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>667.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2051.500000</td>\n",
       "      <td>35.950000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>85.270000</td>\n",
       "      <td>444.200000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.250000e+05</td>\n",
       "      <td>33.650000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>1371.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>90.800000</td>\n",
       "      <td>50.120000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3760.570000</td>\n",
       "      <td>65.720000</td>\n",
       "      <td>6.340000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>704.370000</td>\n",
       "      <td>761.280000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.863000e+05</td>\n",
       "      <td>39.970000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>2090.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>685.420000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>161.650000</td>\n",
       "      <td>73.850000</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5509.430000</td>\n",
       "      <td>65.930000</td>\n",
       "      <td>7.220000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>124.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>1223.480000</td>\n",
       "      <td>1260.370000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>3.304680e+05</td>\n",
       "      <td>52.420000</td>\n",
       "      <td>10.760000</td>\n",
       "      <td>3435.000000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>...</td>\n",
       "      <td>1053.420000</td>\n",
       "      <td>460.980000</td>\n",
       "      <td>265.510000</td>\n",
       "      <td>125.810000</td>\n",
       "      <td>6.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9521.930000</td>\n",
       "      <td>66.130000</td>\n",
       "      <td>7.840000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>352.000000</td>\n",
       "      <td>32389.000000</td>\n",
       "      <td>1893.080000</td>\n",
       "      <td>2724.570000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>7.131500e+07</td>\n",
       "      <td>82.640000</td>\n",
       "      <td>24.690000</td>\n",
       "      <td>160740.000000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>...</td>\n",
       "      <td>11949.330000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>9593.480000</td>\n",
       "      <td>1748.130000</td>\n",
       "      <td>76.630000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55128.460000</td>\n",
       "      <td>66.450000</td>\n",
       "      <td>15.440000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f_1           f_2          f_3          f_4         f_5   \n",
       "count  937.000000    937.000000   937.000000   937.000000  937.000000  \\\n",
       "mean    81.588047    332.842049   698.707086   870.992209   84.121665   \n",
       "std     64.976730   1931.938570   599.965577   522.799325   45.361771   \n",
       "min      1.000000     10.000000     1.920000     1.000000    0.000000   \n",
       "25%     31.000000     20.000000    85.270000   444.200000   54.000000   \n",
       "50%     64.000000     65.000000   704.370000   761.280000   73.000000   \n",
       "75%    124.000000    132.000000  1223.480000  1260.370000  117.000000   \n",
       "max    352.000000  32389.000000  1893.080000  2724.570000  180.000000   \n",
       "\n",
       "                f_6         f_7         f_8            f_9        f_10  ...   \n",
       "count  9.370000e+02  937.000000  937.000000     937.000000  937.000000  ...  \\\n",
       "mean   7.696964e+05   43.242721    9.127887    3940.712914    0.221003  ...   \n",
       "std    3.831151e+06   12.718404    3.588878    8167.427625    0.090316  ...   \n",
       "min    7.031200e+04   21.240000    0.830000     667.000000    0.020000  ...   \n",
       "25%    1.250000e+05   33.650000    6.750000    1371.000000    0.160000  ...   \n",
       "50%    1.863000e+05   39.970000    8.200000    2090.000000    0.200000  ...   \n",
       "75%    3.304680e+05   52.420000   10.760000    3435.000000    0.260000  ...   \n",
       "max    7.131500e+07   82.640000   24.690000  160740.000000    0.740000  ...   \n",
       "\n",
       "               f_41          f_42         f_43         f_44        f_45   \n",
       "count    937.000000    937.000000   937.000000   937.000000  937.000000  \\\n",
       "mean     933.928677    427.565582   255.435902   106.112519    5.014002   \n",
       "std     1001.681331    715.391648   534.306194   135.617708    5.029151   \n",
       "min        0.000000      0.000000     0.000000     0.000000    0.000000   \n",
       "25%      450.000000    180.000000    90.800000    50.120000    2.370000   \n",
       "50%      685.420000    270.000000   161.650000    73.850000    3.850000   \n",
       "75%     1053.420000    460.980000   265.510000   125.810000    6.320000   \n",
       "max    11949.330000  11500.000000  9593.480000  1748.130000   76.630000   \n",
       "\n",
       "             f_46          f_47        f_48        f_49      target  \n",
       "count  937.000000    937.000000  937.000000  937.000000  937.000000  \n",
       "mean     0.128068   7985.718004   61.694386    8.119723    0.043757  \n",
       "std      0.334344   6854.504915   10.412807    2.908895    0.204662  \n",
       "min      0.000000   2051.500000   35.950000    5.810000    0.000000  \n",
       "25%      0.000000   3760.570000   65.720000    6.340000    0.000000  \n",
       "50%      0.000000   5509.430000   65.930000    7.220000    0.000000  \n",
       "75%      0.000000   9521.930000   66.130000    7.840000    0.000000  \n",
       "max      1.000000  55128.460000   66.450000   15.440000    1.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv=df.isnull().sum()\n",
    "nv=nv[nv>0]\n",
    "nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 937 entries, 0 to 936\n",
      "Data columns (total 50 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   f_1     937 non-null    int64  \n",
      " 1   f_2     937 non-null    int64  \n",
      " 2   f_3     937 non-null    float64\n",
      " 3   f_4     937 non-null    float64\n",
      " 4   f_5     937 non-null    int64  \n",
      " 5   f_6     937 non-null    int64  \n",
      " 6   f_7     937 non-null    float64\n",
      " 7   f_8     937 non-null    float64\n",
      " 8   f_9     937 non-null    float64\n",
      " 9   f_10    937 non-null    float64\n",
      " 10  f_11    937 non-null    float64\n",
      " 11  f_12    937 non-null    float64\n",
      " 12  f_13    937 non-null    float64\n",
      " 13  f_14    937 non-null    float64\n",
      " 14  f_15    937 non-null    float64\n",
      " 15  f_16    937 non-null    float64\n",
      " 16  f_17    937 non-null    float64\n",
      " 17  f_18    937 non-null    float64\n",
      " 18  f_19    937 non-null    float64\n",
      " 19  f_20    937 non-null    float64\n",
      " 20  f_21    937 non-null    float64\n",
      " 21  f_22    937 non-null    float64\n",
      " 22  f_23    937 non-null    int64  \n",
      " 23  f_24    937 non-null    float64\n",
      " 24  f_25    937 non-null    float64\n",
      " 25  f_26    937 non-null    float64\n",
      " 26  f_27    937 non-null    float64\n",
      " 27  f_28    937 non-null    float64\n",
      " 28  f_29    937 non-null    float64\n",
      " 29  f_30    937 non-null    float64\n",
      " 30  f_31    937 non-null    float64\n",
      " 31  f_32    937 non-null    float64\n",
      " 32  f_33    937 non-null    float64\n",
      " 33  f_34    937 non-null    float64\n",
      " 34  f_35    937 non-null    int64  \n",
      " 35  f_36    937 non-null    int64  \n",
      " 36  f_37    937 non-null    float64\n",
      " 37  f_38    937 non-null    float64\n",
      " 38  f_39    937 non-null    int64  \n",
      " 39  f_40    937 non-null    int64  \n",
      " 40  f_41    937 non-null    float64\n",
      " 41  f_42    937 non-null    float64\n",
      " 42  f_43    937 non-null    float64\n",
      " 43  f_44    937 non-null    float64\n",
      " 44  f_45    937 non-null    float64\n",
      " 45  f_46    937 non-null    int64  \n",
      " 46  f_47    937 non-null    float64\n",
      " 47  f_48    937 non-null    float64\n",
      " 48  f_49    937 non-null    float64\n",
      " 49  target  937 non-null    int64  \n",
      "dtypes: float64(39), int64(11)\n",
      "memory usage: 366.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix=df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_1\n",
       "3      9\n",
       "5      9\n",
       "6      9\n",
       "8      9\n",
       "9      9\n",
       "      ..\n",
       "261    1\n",
       "266    1\n",
       "267    1\n",
       "269    1\n",
       "204    1\n",
       "Name: count, Length: 238, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['f_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_23\n",
       "0    937\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['f_23'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping Highly Correlated Columns and making a Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>f_11</th>\n",
       "      <th>...</th>\n",
       "      <th>f_41</th>\n",
       "      <th>f_42</th>\n",
       "      <th>f_43</th>\n",
       "      <th>f_44</th>\n",
       "      <th>f_45</th>\n",
       "      <th>f_46</th>\n",
       "      <th>f_47</th>\n",
       "      <th>f_48</th>\n",
       "      <th>f_49</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>214.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>901.7</td>\n",
       "      <td>...</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>86.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>166.5</td>\n",
       "      <td>...</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>232.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>12</td>\n",
       "      <td>92.42</td>\n",
       "      <td>364.42</td>\n",
       "      <td>135</td>\n",
       "      <td>97200</td>\n",
       "      <td>59.42</td>\n",
       "      <td>10.34</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>381.84</td>\n",
       "      <td>254.56</td>\n",
       "      <td>84.85</td>\n",
       "      <td>146.97</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2593.50</td>\n",
       "      <td>65.85</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>11</td>\n",
       "      <td>98.82</td>\n",
       "      <td>248.64</td>\n",
       "      <td>159</td>\n",
       "      <td>89100</td>\n",
       "      <td>59.64</td>\n",
       "      <td>10.18</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>107.2</td>\n",
       "      <td>...</td>\n",
       "      <td>284.60</td>\n",
       "      <td>180.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>51.96</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>4361.25</td>\n",
       "      <td>65.70</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>14</td>\n",
       "      <td>25.14</td>\n",
       "      <td>428.86</td>\n",
       "      <td>24</td>\n",
       "      <td>113400</td>\n",
       "      <td>60.14</td>\n",
       "      <td>17.94</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>133.9</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0</td>\n",
       "      <td>2153.05</td>\n",
       "      <td>65.91</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>10</td>\n",
       "      <td>96.00</td>\n",
       "      <td>451.30</td>\n",
       "      <td>68</td>\n",
       "      <td>81000</td>\n",
       "      <td>59.90</td>\n",
       "      <td>15.01</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>97.5</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>73.48</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2421.43</td>\n",
       "      <td>65.97</td>\n",
       "      <td>6.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>11</td>\n",
       "      <td>7.73</td>\n",
       "      <td>235.73</td>\n",
       "      <td>135</td>\n",
       "      <td>89100</td>\n",
       "      <td>61.82</td>\n",
       "      <td>12.24</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>107.2</td>\n",
       "      <td>...</td>\n",
       "      <td>254.56</td>\n",
       "      <td>254.56</td>\n",
       "      <td>127.28</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3782.68</td>\n",
       "      <td>65.65</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       f_2      f_3     f_4  f_5       f_6    f_7    f_8      f_9  f_10   \n",
       "0     2558  1506.09  456.63   90   6395000  40.88   7.89  29780.0  0.19  \\\n",
       "1    22325    79.11  841.03  180  55812500  51.11   1.21  61900.0  0.02   \n",
       "2      115  1449.85  608.43   88    287500  40.42   7.34   3340.0  0.18   \n",
       "3     1201  1562.53  295.65   66   3002500  42.40   7.97  18030.0  0.19   \n",
       "4      312   950.27  440.86   37    780000  41.43   7.03   3350.0  0.17   \n",
       "..     ...      ...     ...  ...       ...    ...    ...      ...   ...   \n",
       "932     12    92.42  364.42  135     97200  59.42  10.34    884.0  0.17   \n",
       "933     11    98.82  248.64  159     89100  59.64  10.18    831.0  0.17   \n",
       "934     14    25.14  428.86   24    113400  60.14  17.94    847.0  0.30   \n",
       "935     10    96.00  451.30   68     81000  59.90  15.01    831.0  0.25   \n",
       "936     11     7.73  235.73  135     89100  61.82  12.24    831.0  0.20   \n",
       "\n",
       "      f_11  ...     f_41      f_42     f_43     f_44   f_45  f_46      f_47   \n",
       "0    214.7  ...  2850.00   1000.00   763.16   135.46   3.73     0  33243.19  \\\n",
       "1    901.7  ...  5750.00  11500.00  9593.48  1648.80   0.60     0  51572.04   \n",
       "2     86.1  ...  1400.00    250.00   150.00    45.13   9.33     1  31692.84   \n",
       "3    166.5  ...  6041.52    761.58   453.21   144.97  13.33     1  37696.21   \n",
       "4    232.8  ...  1320.04    710.63   512.54   109.16   2.58     0  29038.17   \n",
       "..     ...  ...      ...       ...      ...      ...    ...   ...       ...   \n",
       "932  110.0  ...   381.84    254.56    84.85   146.97   4.50     0   2593.50   \n",
       "933  107.2  ...   284.60    180.00   150.00    51.96   1.90     0   4361.25   \n",
       "934  133.9  ...   402.49    180.00   180.00     0.00   2.24     0   2153.05   \n",
       "935   97.5  ...   402.49    180.00    90.00    73.48   4.47     0   2421.43   \n",
       "936  107.2  ...   254.56    254.56   127.28   180.00   2.00     0   3782.68   \n",
       "\n",
       "      f_48  f_49  target  \n",
       "0    65.74  7.95       1  \n",
       "1    65.73  6.26       0  \n",
       "2    65.81  7.84       1  \n",
       "3    65.67  8.07       1  \n",
       "4    65.66  7.35       0  \n",
       "..     ...   ...     ...  \n",
       "932  65.85  6.39       0  \n",
       "933  65.70  6.53       0  \n",
       "934  65.91  6.12       0  \n",
       "935  65.97  6.32       0  \n",
       "936  65.65  6.26       0  \n",
       "\n",
       "[937 rows x 48 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['f_1','f_23']\n",
    "test=df.drop(columns=columns_to_drop)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 48)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    896\n",
       "1     41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the Dependent and Independent from the Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 47)\n",
      "(937,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "x=test.drop('target',axis=1)\n",
    "y=test['target']\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(type(x))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting thte Training and Testing datas from the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(655, 47)\n",
      "(282, 47)\n",
      "(655,)\n",
      "(282,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_eval(ytest,ypred):\n",
    "    cm = confusion_matrix(ytest,ypred)\n",
    "    print(cm)\n",
    "    print('Accuracy Score', accuracy_score(ytest,ypred))\n",
    "    print(classification_report(ytest,ypred))\n",
    "    \n",
    "def mscore(model):\n",
    "    print('Training Score',model.score(x_train,y_train)) \n",
    "    print('Testing Score',model.score(x_test,y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a model with BAGGING CLASSIFIER ENSEMBLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and Evaluating bagging model with using LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-27 {color: black;}#sk-container-id-27 pre{padding: 0;}#sk-container-id-27 div.sk-toggleable {background-color: white;}#sk-container-id-27 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-27 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-27 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-27 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-27 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-27 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-27 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-27 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-27 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-27 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-27 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-27 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-27 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-27 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-27 div.sk-item {position: relative;z-index: 1;}#sk-container-id-27 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-27 div.sk-item::before, #sk-container-id-27 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-27 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-27 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-27 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-27 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-27 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-27 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-27 div.sk-label-container {text-align: center;}#sk-container-id-27 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-27 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-27\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, random_state=45)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" checked><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, random_state=45)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, random_state=45)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=0.1,max_iter=100,random_state=45)\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score 0.9526717557251908\n",
      "Testing Score 0.950354609929078\n"
     ]
    }
   ],
   "source": [
    "mscore(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred_lr = lr.predict(x_test)\n",
    "ypred_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[265   6]\n",
      " [  8   3]]\n",
      "Accuracy Score 0.950354609929078\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       271\n",
      "           1       0.33      0.27      0.30        11\n",
      "\n",
      "    accuracy                           0.95       282\n",
      "   macro avg       0.65      0.63      0.64       282\n",
      "weighted avg       0.95      0.95      0.95       282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_eval(y_test,ypred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_accuracy score: 0.950354609929078\n"
     ]
    }
   ],
   "source": [
    "lr_accuracy_score = accuracy_score(y_test, ypred_lr)\n",
    "print('LogisticRegression_accuracy score:',lr_accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Building and Evaluating bagging model with using RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-28 {color: black;}#sk-container-id-28 pre{padding: 0;}#sk-container-id-28 div.sk-toggleable {background-color: white;}#sk-container-id-28 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-28 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-28 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-28 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-28 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-28 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-28 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-28 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-28 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-28 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-28 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-28 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-28 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-28 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-28 div.sk-item {position: relative;z-index: 1;}#sk-container-id-28 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-28 div.sk-item::before, #sk-container-id-28 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-28 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-28 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-28 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-28 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-28 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-28 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-28 div.sk-label-container {text-align: center;}#sk-container-id-28 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-28 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-28\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, min_samples_split=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" checked><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, min_samples_split=5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5, min_samples_split=5, random_state=42)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier( n_estimators=100,max_depth=5,min_samples_split=5, max_features='sqrt', random_state=42,criterion='gini')\n",
    "\n",
    "rfc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score 0.9755725190839695\n",
      "Testing Score 0.9645390070921985\n"
     ]
    }
   ],
   "source": [
    "mscore(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred_rfc = rfc.predict(x_test)\n",
    "ypred_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[271   0]\n",
      " [ 10   1]]\n",
      "Accuracy Score 0.9645390070921985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       271\n",
      "           1       1.00      0.09      0.17        11\n",
      "\n",
      "    accuracy                           0.96       282\n",
      "   macro avg       0.98      0.55      0.57       282\n",
      "weighted avg       0.97      0.96      0.95       282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_eval(y_test,ypred_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest_accuracy score: 0.9645390070921985\n"
     ]
    }
   ],
   "source": [
    "rfc_accuracy_score = accuracy_score(y_test, ypred_rfc)\n",
    "print('RandomForest_accuracy score:',rfc_accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and Evaluating the Bagging model with DECISION TREE CLASSIFIER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-29 {color: black;}#sk-container-id-29 pre{padding: 0;}#sk-container-id-29 div.sk-toggleable {background-color: white;}#sk-container-id-29 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-29 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-29 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-29 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-29 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-29 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-29 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-29 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-29 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-29 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-29 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-29 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-29 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-29 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-29 div.sk-item {position: relative;z-index: 1;}#sk-container-id-29 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-29 div.sk-item::before, #sk-container-id-29 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-29 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-29 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-29 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-29 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-29 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-29 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-29 div.sk-label-container {text-align: center;}#sk-container-id-29 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-29 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-29\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5, min_samples_leaf=5, min_samples_split=10,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" checked><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5, min_samples_leaf=5, min_samples_split=10,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, min_samples_leaf=5, min_samples_split=10,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=5,min_samples_leaf=5,min_samples_split=10,random_state=42,criterion='gini')\n",
    "\n",
    "dtc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score 0.9801526717557252\n",
      "Testing Score 0.9609929078014184\n"
     ]
    }
   ],
   "source": [
    "mscore(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred_dtc = dtc.predict(x_test)\n",
    "ypred_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[268   3]\n",
      " [  8   3]]\n",
      "Accuracy Score 0.9609929078014184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       271\n",
      "           1       0.50      0.27      0.35        11\n",
      "\n",
      "    accuracy                           0.96       282\n",
      "   macro avg       0.74      0.63      0.67       282\n",
      "weighted avg       0.95      0.96      0.96       282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_eval(y_test,ypred_dtc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9609929078014184\n"
     ]
    }
   ],
   "source": [
    "accuracy_score_dtc = accuracy_score(y_test, ypred_dtc)\n",
    "print(\"Accuracy Score:\",  accuracy_score_dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression Model is 0.950354609929078\n",
      "Accuracy of Random Forest Classifier Model is 0.9645390070921985\n",
      "Accuracy of Decision Tree Classifier Model is 0.9609929078014184\n"
     ]
    }
   ],
   "source": [
    "acc_log = accuracy_score(y_test,ypred_lr)\n",
    "acc_randf = accuracy_score(y_test,ypred_rfc)\n",
    "acc_dec = accuracy_score(y_test,ypred_dtc)\n",
    "\n",
    "print('Accuracy of LogisticRegression Model is',acc_log)\n",
    "print('Accuracy of Random Forest Classifier Model is',acc_randf)\n",
    "print('Accuracy of Decision Tree Classifier Model is',acc_dec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random forest classifier has the highest accuracy score. so i chosen that Random forest classifier as a Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f_2', 'f_3', 'f_4', 'f_5', 'f_6', 'f_7', 'f_8', 'f_9', 'f_10', 'f_11',\n",
       "       'f_12', 'f_13', 'f_14', 'f_15', 'f_16', 'f_17', 'f_18', 'f_19', 'f_20',\n",
       "       'f_21', 'f_22', 'f_24', 'f_25', 'f_26', 'f_27', 'f_28', 'f_29', 'f_30',\n",
       "       'f_31', 'f_32', 'f_33', 'f_34', 'f_35', 'f_36', 'f_37', 'f_38', 'f_39',\n",
       "       'f_40', 'f_41', 'f_42', 'f_43', 'f_44', 'f_45', 'f_46', 'f_47', 'f_48',\n",
       "       'f_49', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f_2', 'f_3', 'f_4', 'f_5', 'f_6', 'f_7', 'f_8', 'f_9', 'f_10', 'f_11',\n",
       "       'f_12', 'f_13', 'f_14', 'f_15', 'f_16', 'f_17', 'f_18', 'f_19', 'f_20',\n",
       "       'f_21', 'f_22', 'f_24', 'f_25', 'f_26', 'f_27', 'f_28', 'f_29', 'f_30',\n",
       "       'f_31', 'f_32', 'f_33', 'f_34', 'f_35', 'f_36', 'f_37', 'f_38', 'f_39',\n",
       "       'f_40', 'f_41', 'f_42', 'f_43', 'f_44', 'f_45', 'f_46', 'f_47', 'f_48',\n",
       "       'f_49'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred =rfc.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted values of Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>f_11</th>\n",
       "      <th>...</th>\n",
       "      <th>f_42</th>\n",
       "      <th>f_43</th>\n",
       "      <th>f_44</th>\n",
       "      <th>f_45</th>\n",
       "      <th>f_46</th>\n",
       "      <th>f_47</th>\n",
       "      <th>f_48</th>\n",
       "      <th>f_49</th>\n",
       "      <th>target</th>\n",
       "      <th>count_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>214.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>901.7</td>\n",
       "      <td>...</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>86.1</td>\n",
       "      <td>...</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>166.5</td>\n",
       "      <td>...</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>232.8</td>\n",
       "      <td>...</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54</td>\n",
       "      <td>1438.13</td>\n",
       "      <td>544.91</td>\n",
       "      <td>82</td>\n",
       "      <td>135000</td>\n",
       "      <td>44.67</td>\n",
       "      <td>6.92</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>52.22</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0</td>\n",
       "      <td>30967.25</td>\n",
       "      <td>65.77</td>\n",
       "      <td>7.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>116</td>\n",
       "      <td>1446.29</td>\n",
       "      <td>580.94</td>\n",
       "      <td>97</td>\n",
       "      <td>290000</td>\n",
       "      <td>41.53</td>\n",
       "      <td>6.24</td>\n",
       "      <td>3660.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>79.2</td>\n",
       "      <td>...</td>\n",
       "      <td>403.11</td>\n",
       "      <td>164.58</td>\n",
       "      <td>114.82</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>31258.37</td>\n",
       "      <td>65.79</td>\n",
       "      <td>7.85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>57</td>\n",
       "      <td>28.68</td>\n",
       "      <td>715.39</td>\n",
       "      <td>141</td>\n",
       "      <td>142500</td>\n",
       "      <td>51.67</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>78.7</td>\n",
       "      <td>...</td>\n",
       "      <td>360.56</td>\n",
       "      <td>165.71</td>\n",
       "      <td>132.47</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0</td>\n",
       "      <td>51985.06</td>\n",
       "      <td>65.67</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>188</td>\n",
       "      <td>964.23</td>\n",
       "      <td>456.23</td>\n",
       "      <td>22</td>\n",
       "      <td>470000</td>\n",
       "      <td>38.90</td>\n",
       "      <td>5.89</td>\n",
       "      <td>3720.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>126.3</td>\n",
       "      <td>...</td>\n",
       "      <td>492.44</td>\n",
       "      <td>256.77</td>\n",
       "      <td>124.72</td>\n",
       "      <td>6.11</td>\n",
       "      <td>0</td>\n",
       "      <td>28871.82</td>\n",
       "      <td>65.67</td>\n",
       "      <td>7.36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>903.02</td>\n",
       "      <td>274.88</td>\n",
       "      <td>33</td>\n",
       "      <td>160000</td>\n",
       "      <td>41.22</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>86.5</td>\n",
       "      <td>...</td>\n",
       "      <td>223.61</td>\n",
       "      <td>182.83</td>\n",
       "      <td>50.12</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>32053.95</td>\n",
       "      <td>65.58</td>\n",
       "      <td>7.35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>59</td>\n",
       "      <td>1127.41</td>\n",
       "      <td>1507.76</td>\n",
       "      <td>42</td>\n",
       "      <td>147500</td>\n",
       "      <td>47.59</td>\n",
       "      <td>4.72</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>81.9</td>\n",
       "      <td>...</td>\n",
       "      <td>212.13</td>\n",
       "      <td>120.21</td>\n",
       "      <td>47.73</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0</td>\n",
       "      <td>55128.46</td>\n",
       "      <td>66.18</td>\n",
       "      <td>7.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>329</td>\n",
       "      <td>1627.54</td>\n",
       "      <td>1409.43</td>\n",
       "      <td>51</td>\n",
       "      <td>822500</td>\n",
       "      <td>35.00</td>\n",
       "      <td>6.10</td>\n",
       "      <td>4610.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>178.4</td>\n",
       "      <td>...</td>\n",
       "      <td>710.63</td>\n",
       "      <td>451.78</td>\n",
       "      <td>150.85</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0</td>\n",
       "      <td>4530.75</td>\n",
       "      <td>66.25</td>\n",
       "      <td>7.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3234</td>\n",
       "      <td>1091.56</td>\n",
       "      <td>1357.96</td>\n",
       "      <td>32</td>\n",
       "      <td>8085000</td>\n",
       "      <td>40.08</td>\n",
       "      <td>8.98</td>\n",
       "      <td>25450.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>317.7</td>\n",
       "      <td>...</td>\n",
       "      <td>3095.56</td>\n",
       "      <td>1937.42</td>\n",
       "      <td>773.69</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0</td>\n",
       "      <td>4927.51</td>\n",
       "      <td>66.15</td>\n",
       "      <td>7.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2339</td>\n",
       "      <td>1537.68</td>\n",
       "      <td>1633.02</td>\n",
       "      <td>45</td>\n",
       "      <td>5847500</td>\n",
       "      <td>38.13</td>\n",
       "      <td>9.29</td>\n",
       "      <td>22110.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>264.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2404.16</td>\n",
       "      <td>1530.38</td>\n",
       "      <td>659.67</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0</td>\n",
       "      <td>4732.04</td>\n",
       "      <td>66.34</td>\n",
       "      <td>7.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2971</td>\n",
       "      <td>1020.91</td>\n",
       "      <td>630.80</td>\n",
       "      <td>59</td>\n",
       "      <td>7427500</td>\n",
       "      <td>32.76</td>\n",
       "      <td>10.48</td>\n",
       "      <td>17380.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>427.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1749.29</td>\n",
       "      <td>1245.07</td>\n",
       "      <td>348.70</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0</td>\n",
       "      <td>25579.34</td>\n",
       "      <td>65.78</td>\n",
       "      <td>7.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3155</td>\n",
       "      <td>1118.08</td>\n",
       "      <td>469.39</td>\n",
       "      <td>11</td>\n",
       "      <td>7887500</td>\n",
       "      <td>30.41</td>\n",
       "      <td>7.99</td>\n",
       "      <td>15880.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>496.7</td>\n",
       "      <td>...</td>\n",
       "      <td>3059.41</td>\n",
       "      <td>2043.90</td>\n",
       "      <td>477.23</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0</td>\n",
       "      <td>28172.07</td>\n",
       "      <td>65.72</td>\n",
       "      <td>7.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11475</td>\n",
       "      <td>1249.47</td>\n",
       "      <td>1386.03</td>\n",
       "      <td>41</td>\n",
       "      <td>28687500</td>\n",
       "      <td>38.57</td>\n",
       "      <td>9.50</td>\n",
       "      <td>58790.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>488.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4816.64</td>\n",
       "      <td>3894.10</td>\n",
       "      <td>593.54</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0</td>\n",
       "      <td>5514.48</td>\n",
       "      <td>66.18</td>\n",
       "      <td>7.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1034</td>\n",
       "      <td>1776.55</td>\n",
       "      <td>1464.70</td>\n",
       "      <td>52</td>\n",
       "      <td>2585000</td>\n",
       "      <td>39.30</td>\n",
       "      <td>14.51</td>\n",
       "      <td>12990.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1140.18</td>\n",
       "      <td>651.51</td>\n",
       "      <td>300.07</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0</td>\n",
       "      <td>4535.86</td>\n",
       "      <td>66.29</td>\n",
       "      <td>8.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1035</td>\n",
       "      <td>1304.90</td>\n",
       "      <td>1281.72</td>\n",
       "      <td>68</td>\n",
       "      <td>2587500</td>\n",
       "      <td>35.90</td>\n",
       "      <td>7.51</td>\n",
       "      <td>15420.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>167.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1234.91</td>\n",
       "      <td>632.82</td>\n",
       "      <td>358.06</td>\n",
       "      <td>6.98</td>\n",
       "      <td>0</td>\n",
       "      <td>6165.56</td>\n",
       "      <td>66.14</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4851</td>\n",
       "      <td>1700.15</td>\n",
       "      <td>1345.04</td>\n",
       "      <td>52</td>\n",
       "      <td>12127500</td>\n",
       "      <td>34.47</td>\n",
       "      <td>7.60</td>\n",
       "      <td>49430.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>245.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2600.48</td>\n",
       "      <td>1983.69</td>\n",
       "      <td>387.60</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0</td>\n",
       "      <td>4236.17</td>\n",
       "      <td>66.23</td>\n",
       "      <td>7.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2899</td>\n",
       "      <td>1533.91</td>\n",
       "      <td>1713.00</td>\n",
       "      <td>45</td>\n",
       "      <td>7247500</td>\n",
       "      <td>41.88</td>\n",
       "      <td>11.07</td>\n",
       "      <td>21180.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>342.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2050.61</td>\n",
       "      <td>1506.78</td>\n",
       "      <td>307.58</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>4084.14</td>\n",
       "      <td>66.38</td>\n",
       "      <td>7.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1655</td>\n",
       "      <td>1761.30</td>\n",
       "      <td>1430.22</td>\n",
       "      <td>90</td>\n",
       "      <td>4137500</td>\n",
       "      <td>35.38</td>\n",
       "      <td>9.05</td>\n",
       "      <td>21570.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>191.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2450.00</td>\n",
       "      <td>1645.45</td>\n",
       "      <td>302.87</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>4402.70</td>\n",
       "      <td>66.27</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2664</td>\n",
       "      <td>1344.49</td>\n",
       "      <td>1363.74</td>\n",
       "      <td>45</td>\n",
       "      <td>6660000</td>\n",
       "      <td>38.72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>28160.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>236.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5020.46</td>\n",
       "      <td>4531.14</td>\n",
       "      <td>247.42</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0</td>\n",
       "      <td>6602.97</td>\n",
       "      <td>66.19</td>\n",
       "      <td>7.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>936</td>\n",
       "      <td>1095.47</td>\n",
       "      <td>1416.49</td>\n",
       "      <td>54</td>\n",
       "      <td>2340000</td>\n",
       "      <td>41.06</td>\n",
       "      <td>8.16</td>\n",
       "      <td>10920.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>214.3</td>\n",
       "      <td>...</td>\n",
       "      <td>860.23</td>\n",
       "      <td>587.69</td>\n",
       "      <td>156.73</td>\n",
       "      <td>5.79</td>\n",
       "      <td>0</td>\n",
       "      <td>5500.47</td>\n",
       "      <td>66.18</td>\n",
       "      <td>7.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>486</td>\n",
       "      <td>1628.99</td>\n",
       "      <td>1627.11</td>\n",
       "      <td>39</td>\n",
       "      <td>1215000</td>\n",
       "      <td>36.71</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7820.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>155.4</td>\n",
       "      <td>...</td>\n",
       "      <td>890.22</td>\n",
       "      <td>368.89</td>\n",
       "      <td>213.81</td>\n",
       "      <td>7.81</td>\n",
       "      <td>0</td>\n",
       "      <td>3792.61</td>\n",
       "      <td>66.35</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>851</td>\n",
       "      <td>1422.20</td>\n",
       "      <td>1749.68</td>\n",
       "      <td>34</td>\n",
       "      <td>2127500</td>\n",
       "      <td>33.83</td>\n",
       "      <td>8.27</td>\n",
       "      <td>9520.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>223.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1484.08</td>\n",
       "      <td>728.86</td>\n",
       "      <td>354.07</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0</td>\n",
       "      <td>6334.81</td>\n",
       "      <td>66.39</td>\n",
       "      <td>7.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1396</td>\n",
       "      <td>1608.04</td>\n",
       "      <td>1545.25</td>\n",
       "      <td>54</td>\n",
       "      <td>3490000</td>\n",
       "      <td>34.37</td>\n",
       "      <td>8.36</td>\n",
       "      <td>18590.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>187.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1390.14</td>\n",
       "      <td>875.39</td>\n",
       "      <td>366.64</td>\n",
       "      <td>5.31</td>\n",
       "      <td>0</td>\n",
       "      <td>3508.48</td>\n",
       "      <td>66.31</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2503</td>\n",
       "      <td>1501.49</td>\n",
       "      <td>1141.62</td>\n",
       "      <td>90</td>\n",
       "      <td>6257500</td>\n",
       "      <td>33.76</td>\n",
       "      <td>9.43</td>\n",
       "      <td>29030.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>215.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3150.00</td>\n",
       "      <td>2338.39</td>\n",
       "      <td>400.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0</td>\n",
       "      <td>5267.92</td>\n",
       "      <td>66.10</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>65</td>\n",
       "      <td>1579.09</td>\n",
       "      <td>995.74</td>\n",
       "      <td>43</td>\n",
       "      <td>162500</td>\n",
       "      <td>38.34</td>\n",
       "      <td>5.89</td>\n",
       "      <td>2350.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>69.1</td>\n",
       "      <td>...</td>\n",
       "      <td>141.42</td>\n",
       "      <td>62.39</td>\n",
       "      <td>55.24</td>\n",
       "      <td>18.71</td>\n",
       "      <td>1</td>\n",
       "      <td>6298.61</td>\n",
       "      <td>66.04</td>\n",
       "      <td>7.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>191</td>\n",
       "      <td>1732.70</td>\n",
       "      <td>1238.70</td>\n",
       "      <td>36</td>\n",
       "      <td>477500</td>\n",
       "      <td>39.80</td>\n",
       "      <td>6.71</td>\n",
       "      <td>5050.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>94.6</td>\n",
       "      <td>...</td>\n",
       "      <td>570.09</td>\n",
       "      <td>299.41</td>\n",
       "      <td>124.78</td>\n",
       "      <td>5.48</td>\n",
       "      <td>0</td>\n",
       "      <td>4663.21</td>\n",
       "      <td>66.18</td>\n",
       "      <td>8.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      f_2      f_3      f_4  f_5       f_6    f_7    f_8      f_9  f_10   \n",
       "0    2558  1506.09   456.63   90   6395000  40.88   7.89  29780.0  0.19  \\\n",
       "1   22325    79.11   841.03  180  55812500  51.11   1.21  61900.0  0.02   \n",
       "2     115  1449.85   608.43   88    287500  40.42   7.34   3340.0  0.18   \n",
       "3    1201  1562.53   295.65   66   3002500  42.40   7.97  18030.0  0.19   \n",
       "4     312   950.27   440.86   37    780000  41.43   7.03   3350.0  0.17   \n",
       "5      54  1438.13   544.91   82    135000  44.67   6.92   1570.0  0.15   \n",
       "6     116  1446.29   580.94   97    290000  41.53   6.24   3660.0  0.15   \n",
       "7      57    28.68   715.39  141    142500  51.67   0.83   1810.0  0.02   \n",
       "8     188   964.23   456.23   22    470000  38.90   5.89   3720.0  0.15   \n",
       "9      64   903.02   274.88   33    160000  41.22   7.90   1850.0  0.19   \n",
       "10     59  1127.41  1507.76   42    147500  47.59   4.72   1800.0  0.10   \n",
       "11    329  1627.54  1409.43   51    822500  35.00   6.10   4610.0  0.17   \n",
       "12   3234  1091.56  1357.96   32   8085000  40.08   8.98  25450.0  0.22   \n",
       "13   2339  1537.68  1633.02   45   5847500  38.13   9.29  22110.0  0.24   \n",
       "14   2971  1020.91   630.80   59   7427500  32.76  10.48  17380.0  0.32   \n",
       "15   3155  1118.08   469.39   11   7887500  30.41   7.99  15880.0  0.26   \n",
       "16  11475  1249.47  1386.03   41  28687500  38.57   9.50  58790.0  0.25   \n",
       "17   1034  1776.55  1464.70   52   2585000  39.30  14.51  12990.0  0.37   \n",
       "18   1035  1304.90  1281.72   68   2587500  35.90   7.51  15420.0  0.21   \n",
       "19   4851  1700.15  1345.04   52  12127500  34.47   7.60  49430.0  0.22   \n",
       "20   2899  1533.91  1713.00   45   7247500  41.88  11.07  21180.0  0.26   \n",
       "21   1655  1761.30  1430.22   90   4137500  35.38   9.05  21570.0  0.26   \n",
       "22   2664  1344.49  1363.74   45   6660000  38.72   8.75  28160.0  0.23   \n",
       "23    936  1095.47  1416.49   54   2340000  41.06   8.16  10920.0  0.20   \n",
       "24    486  1628.99  1627.11   39   1215000  36.71   9.49   7820.0  0.26   \n",
       "25    851  1422.20  1749.68   34   2127500  33.83   8.27   9520.0  0.24   \n",
       "26   1396  1608.04  1545.25   54   3490000  34.37   8.36  18590.0  0.24   \n",
       "27   2503  1501.49  1141.62   90   6257500  33.76   9.43  29030.0  0.28   \n",
       "28     65  1579.09   995.74   43    162500  38.34   5.89   2350.0  0.15   \n",
       "29    191  1732.70  1238.70   36    477500  39.80   6.71   5050.0  0.17   \n",
       "\n",
       "     f_11  ...      f_42     f_43     f_44   f_45  f_46      f_47   f_48   \n",
       "0   214.7  ...   1000.00   763.16   135.46   3.73     0  33243.19  65.74  \\\n",
       "1   901.7  ...  11500.00  9593.48  1648.80   0.60     0  51572.04  65.73   \n",
       "2    86.1  ...    250.00   150.00    45.13   9.33     1  31692.84  65.81   \n",
       "3   166.5  ...    761.58   453.21   144.97  13.33     1  37696.21  65.67   \n",
       "4   232.8  ...    710.63   512.54   109.16   2.58     0  29038.17  65.66   \n",
       "5    86.0  ...    200.00   150.00    52.22   4.06     0  30967.25  65.77   \n",
       "6    79.2  ...    403.11   164.58   114.82   6.44     0  31258.37  65.79   \n",
       "7    78.7  ...    360.56   165.71   132.47   3.02     0  51985.06  65.67   \n",
       "8   126.3  ...    492.44   256.77   124.72   6.11     0  28871.82  65.67   \n",
       "9    86.5  ...    223.61   182.83    50.12   2.58     0  32053.95  65.58   \n",
       "10   81.9  ...    212.13   120.21    47.73   5.88     0  55128.46  66.18   \n",
       "11  178.4  ...    710.63   451.78   150.85   3.23     0   4530.75  66.25   \n",
       "12  317.7  ...   3095.56  1937.42   773.69   2.21     0   4927.51  66.15   \n",
       "13  264.5  ...   2404.16  1530.38   659.67   2.59     0   4732.04  66.34   \n",
       "14  427.4  ...   1749.29  1245.07   348.70   4.54     0  25579.34  65.78   \n",
       "15  496.7  ...   3059.41  2043.90   477.23   1.70     0  28172.07  65.72   \n",
       "16  488.0  ...   4816.64  3894.10   593.54   1.63     0   5514.48  66.18   \n",
       "17  199.0  ...   1140.18   651.51   300.07   5.80     0   4535.86  66.29   \n",
       "18  167.8  ...   1234.91   632.82   358.06   6.98     0   6165.56  66.14   \n",
       "19  245.3  ...   2600.48  1983.69   387.60   1.60     0   4236.17  66.23   \n",
       "20  342.2  ...   2050.61  1506.78   307.58   2.58     0   4084.14  66.38   \n",
       "21  191.8  ...   2450.00  1645.45   302.87   0.33     0   4402.70  66.27   \n",
       "22  236.5  ...   5020.46  4531.14   247.42   0.39     0   6602.97  66.19   \n",
       "23  214.3  ...    860.23   587.69   156.73   5.79     0   5500.47  66.18   \n",
       "24  155.4  ...    890.22   368.89   213.81   7.81     0   3792.61  66.35   \n",
       "25  223.5  ...   1484.08   728.86   354.07   3.65     0   6334.81  66.39   \n",
       "26  187.7  ...   1390.14   875.39   366.64   5.31     0   3508.48  66.31   \n",
       "27  215.6  ...   3150.00  2338.39   400.00   1.20     0   5267.92  66.10   \n",
       "28   69.1  ...    141.42    62.39    55.24  18.71     1   6298.61  66.04   \n",
       "29   94.6  ...    570.09   299.41   124.78   5.48     0   4663.21  66.18   \n",
       "\n",
       "    f_49  target  count_pred  \n",
       "0   7.95       1           1  \n",
       "1   6.26       0           0  \n",
       "2   7.84       1           1  \n",
       "3   8.07       1           1  \n",
       "4   7.35       0           0  \n",
       "5   7.85       1           0  \n",
       "6   7.85       1           1  \n",
       "7   6.25       0           0  \n",
       "8   7.36       1           1  \n",
       "9   7.35       1           1  \n",
       "10  7.18       1           0  \n",
       "11  7.85       0           0  \n",
       "12  7.24       0           0  \n",
       "13  7.67       0           0  \n",
       "14  7.41       1           1  \n",
       "15  7.58       1           1  \n",
       "16  7.41       0           0  \n",
       "17  8.01       0           0  \n",
       "18  7.52       0           0  \n",
       "19  7.96       0           0  \n",
       "20  7.63       0           0  \n",
       "21  8.00       0           0  \n",
       "22  7.53       0           0  \n",
       "23  7.22       0           0  \n",
       "24  7.78       0           0  \n",
       "25  7.49       0           0  \n",
       "26  7.78       0           0  \n",
       "27  7.80       0           0  \n",
       "28  7.94       0           0  \n",
       "29  8.04       0           0  \n",
       "\n",
       "[30 rows x 49 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['count_pred']=test_pred\n",
    "test.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading predicted values of a test dataset into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('oilspill_prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the best model in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>...</th>\n",
       "      <th>f_41</th>\n",
       "      <th>f_42</th>\n",
       "      <th>f_43</th>\n",
       "      <th>f_44</th>\n",
       "      <th>f_45</th>\n",
       "      <th>f_46</th>\n",
       "      <th>f_47</th>\n",
       "      <th>f_48</th>\n",
       "      <th>f_49</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>200</td>\n",
       "      <td>12</td>\n",
       "      <td>92.42</td>\n",
       "      <td>364.42</td>\n",
       "      <td>135</td>\n",
       "      <td>97200</td>\n",
       "      <td>59.42</td>\n",
       "      <td>10.34</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>381.84</td>\n",
       "      <td>254.56</td>\n",
       "      <td>84.85</td>\n",
       "      <td>146.97</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2593.50</td>\n",
       "      <td>65.85</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>201</td>\n",
       "      <td>11</td>\n",
       "      <td>98.82</td>\n",
       "      <td>248.64</td>\n",
       "      <td>159</td>\n",
       "      <td>89100</td>\n",
       "      <td>59.64</td>\n",
       "      <td>10.18</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>284.60</td>\n",
       "      <td>180.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>51.96</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>4361.25</td>\n",
       "      <td>65.70</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>202</td>\n",
       "      <td>14</td>\n",
       "      <td>25.14</td>\n",
       "      <td>428.86</td>\n",
       "      <td>24</td>\n",
       "      <td>113400</td>\n",
       "      <td>60.14</td>\n",
       "      <td>17.94</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0</td>\n",
       "      <td>2153.05</td>\n",
       "      <td>65.91</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>203</td>\n",
       "      <td>10</td>\n",
       "      <td>96.00</td>\n",
       "      <td>451.30</td>\n",
       "      <td>68</td>\n",
       "      <td>81000</td>\n",
       "      <td>59.90</td>\n",
       "      <td>15.01</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>73.48</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2421.43</td>\n",
       "      <td>65.97</td>\n",
       "      <td>6.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>204</td>\n",
       "      <td>11</td>\n",
       "      <td>7.73</td>\n",
       "      <td>235.73</td>\n",
       "      <td>135</td>\n",
       "      <td>89100</td>\n",
       "      <td>61.82</td>\n",
       "      <td>12.24</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>254.56</td>\n",
       "      <td>254.56</td>\n",
       "      <td>127.28</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3782.68</td>\n",
       "      <td>65.65</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     f_1    f_2      f_3     f_4  f_5       f_6    f_7    f_8      f_9  f_10   \n",
       "0      1   2558  1506.09  456.63   90   6395000  40.88   7.89  29780.0  0.19  \\\n",
       "1      2  22325    79.11  841.03  180  55812500  51.11   1.21  61900.0  0.02   \n",
       "2      3    115  1449.85  608.43   88    287500  40.42   7.34   3340.0  0.18   \n",
       "3      4   1201  1562.53  295.65   66   3002500  42.40   7.97  18030.0  0.19   \n",
       "4      5    312   950.27  440.86   37    780000  41.43   7.03   3350.0  0.17   \n",
       "..   ...    ...      ...     ...  ...       ...    ...    ...      ...   ...   \n",
       "932  200     12    92.42  364.42  135     97200  59.42  10.34    884.0  0.17   \n",
       "933  201     11    98.82  248.64  159     89100  59.64  10.18    831.0  0.17   \n",
       "934  202     14    25.14  428.86   24    113400  60.14  17.94    847.0  0.30   \n",
       "935  203     10    96.00  451.30   68     81000  59.90  15.01    831.0  0.25   \n",
       "936  204     11     7.73  235.73  135     89100  61.82  12.24    831.0  0.20   \n",
       "\n",
       "     ...     f_41      f_42     f_43     f_44   f_45  f_46      f_47   f_48   \n",
       "0    ...  2850.00   1000.00   763.16   135.46   3.73     0  33243.19  65.74  \\\n",
       "1    ...  5750.00  11500.00  9593.48  1648.80   0.60     0  51572.04  65.73   \n",
       "2    ...  1400.00    250.00   150.00    45.13   9.33     1  31692.84  65.81   \n",
       "3    ...  6041.52    761.58   453.21   144.97  13.33     1  37696.21  65.67   \n",
       "4    ...  1320.04    710.63   512.54   109.16   2.58     0  29038.17  65.66   \n",
       "..   ...      ...       ...      ...      ...    ...   ...       ...    ...   \n",
       "932  ...   381.84    254.56    84.85   146.97   4.50     0   2593.50  65.85   \n",
       "933  ...   284.60    180.00   150.00    51.96   1.90     0   4361.25  65.70   \n",
       "934  ...   402.49    180.00   180.00     0.00   2.24     0   2153.05  65.91   \n",
       "935  ...   402.49    180.00    90.00    73.48   4.47     0   2421.43  65.97   \n",
       "936  ...   254.56    254.56   127.28   180.00   2.00     0   3782.68  65.65   \n",
       "\n",
       "     f_49  target  \n",
       "0    7.95       1  \n",
       "1    6.26       0  \n",
       "2    7.84       1  \n",
       "3    8.07       1  \n",
       "4    7.35       0  \n",
       "..    ...     ...  \n",
       "932  6.39       0  \n",
       "933  6.53       0  \n",
       "934  6.12       0  \n",
       "935  6.32       0  \n",
       "936  6.26       0  \n",
       "\n",
       "[937 rows x 50 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data=pd.read_csv(r'G:\\My Drive\\oil_spill.csv')\n",
    "original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 47)\n",
      "(937,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "i=original_data.drop('target',axis=1)\n",
    "j=original_data['target']\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(type(x))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(655, 49)\n",
      "(282, 49)\n",
      "(655,)\n",
      "(282,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "i_train,i_test,j_train,j_test=train_test_split(i,j,test_size=0.30,random_state=42)\n",
    "print(i_train.shape)\n",
    "print(i_test.shape)\n",
    "print(j_train.shape)\n",
    "print(j_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_eval(jtest,jpred):\n",
    "    cm = confusion_matrix(jtest,jpred)\n",
    "    print(cm)\n",
    "    print('Accuracy Score', accuracy_score(jtest,jpred))\n",
    "    print(classification_report(jtest,jpred))\n",
    "    \n",
    "def mscore(model):\n",
    "    print('Training Score',model.score(i_train,j_train)) \n",
    "    print('Testing Score',model.score(i_test,j_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-30 {color: black;}#sk-container-id-30 pre{padding: 0;}#sk-container-id-30 div.sk-toggleable {background-color: white;}#sk-container-id-30 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-30 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-30 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-30 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-30 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-30 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-30 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-30 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-30 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-30 div.sk-item {position: relative;z-index: 1;}#sk-container-id-30 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-30 div.sk-item::before, #sk-container-id-30 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-30 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-30 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-30 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-30 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-30 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-30 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-30 div.sk-label-container {text-align: center;}#sk-container-id-30 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-30 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, min_samples_split=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, min_samples_split=5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5, min_samples_split=5, random_state=42)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier( n_estimators=100,max_depth=5,min_samples_split=5, max_features='sqrt', random_state=42,criterion='gini')\n",
    "\n",
    "rand_forest.fit(i_train, j_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score 0.9755725190839695\n",
      "Testing Score 0.9680851063829787\n"
     ]
    }
   ],
   "source": [
    "mscore(rand_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpred_rand_forest = rand_forest.predict(i_test)\n",
    "jpred_rand_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[270   1]\n",
      " [  8   3]]\n",
      "Accuracy Score 0.9680851063829787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       271\n",
      "           1       0.75      0.27      0.40        11\n",
      "\n",
      "    accuracy                           0.97       282\n",
      "   macro avg       0.86      0.63      0.69       282\n",
      "weighted avg       0.96      0.97      0.96       282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_eval(j_test,jpred_rand_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest_accuracy score for original dataset: 0.9680851063829787\n"
     ]
    }
   ],
   "source": [
    "rand_forest_accuracy_score = accuracy_score(j_test, jpred_rand_forest)\n",
    "print('RandomForest_accuracy score for original dataset:',rand_forest_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f_1', 'f_2', 'f_3', 'f_4', 'f_5', 'f_6', 'f_7', 'f_8', 'f_9', 'f_10',\n",
       "       'f_11', 'f_12', 'f_13', 'f_14', 'f_15', 'f_16', 'f_17', 'f_18', 'f_19',\n",
       "       'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25', 'f_26', 'f_27', 'f_28',\n",
       "       'f_29', 'f_30', 'f_31', 'f_32', 'f_33', 'f_34', 'f_35', 'f_36', 'f_37',\n",
       "       'f_38', 'f_39', 'f_40', 'f_41', 'f_42', 'f_43', 'f_44', 'f_45', 'f_46',\n",
       "       'f_47', 'f_48', 'f_49', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f_1', 'f_2', 'f_3', 'f_4', 'f_5', 'f_6', 'f_7', 'f_8', 'f_9', 'f_10',\n",
       "       'f_11', 'f_12', 'f_13', 'f_14', 'f_15', 'f_16', 'f_17', 'f_18', 'f_19',\n",
       "       'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25', 'f_26', 'f_27', 'f_28',\n",
       "       'f_29', 'f_30', 'f_31', 'f_32', 'f_33', 'f_34', 'f_35', 'f_36', 'f_37',\n",
       "       'f_38', 'f_39', 'f_40', 'f_41', 'f_42', 'f_43', 'f_44', 'f_45', 'f_46',\n",
       "       'f_47', 'f_48', 'f_49'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_pred =rand_forest.predict(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Datasets Prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>...</th>\n",
       "      <th>f_42</th>\n",
       "      <th>f_43</th>\n",
       "      <th>f_44</th>\n",
       "      <th>f_45</th>\n",
       "      <th>f_46</th>\n",
       "      <th>f_47</th>\n",
       "      <th>f_48</th>\n",
       "      <th>f_49</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>1438.13</td>\n",
       "      <td>544.91</td>\n",
       "      <td>82</td>\n",
       "      <td>135000</td>\n",
       "      <td>44.67</td>\n",
       "      <td>6.92</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>200.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>52.22</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0</td>\n",
       "      <td>30967.25</td>\n",
       "      <td>65.77</td>\n",
       "      <td>7.85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>116</td>\n",
       "      <td>1446.29</td>\n",
       "      <td>580.94</td>\n",
       "      <td>97</td>\n",
       "      <td>290000</td>\n",
       "      <td>41.53</td>\n",
       "      <td>6.24</td>\n",
       "      <td>3660.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>403.11</td>\n",
       "      <td>164.58</td>\n",
       "      <td>114.82</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>31258.37</td>\n",
       "      <td>65.79</td>\n",
       "      <td>7.85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>57</td>\n",
       "      <td>28.68</td>\n",
       "      <td>715.39</td>\n",
       "      <td>141</td>\n",
       "      <td>142500</td>\n",
       "      <td>51.67</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>360.56</td>\n",
       "      <td>165.71</td>\n",
       "      <td>132.47</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0</td>\n",
       "      <td>51985.06</td>\n",
       "      <td>65.67</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>188</td>\n",
       "      <td>964.23</td>\n",
       "      <td>456.23</td>\n",
       "      <td>22</td>\n",
       "      <td>470000</td>\n",
       "      <td>38.90</td>\n",
       "      <td>5.89</td>\n",
       "      <td>3720.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>492.44</td>\n",
       "      <td>256.77</td>\n",
       "      <td>124.72</td>\n",
       "      <td>6.11</td>\n",
       "      <td>0</td>\n",
       "      <td>28871.82</td>\n",
       "      <td>65.67</td>\n",
       "      <td>7.36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>903.02</td>\n",
       "      <td>274.88</td>\n",
       "      <td>33</td>\n",
       "      <td>160000</td>\n",
       "      <td>41.22</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>223.61</td>\n",
       "      <td>182.83</td>\n",
       "      <td>50.12</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>32053.95</td>\n",
       "      <td>65.58</td>\n",
       "      <td>7.35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>59</td>\n",
       "      <td>1127.41</td>\n",
       "      <td>1507.76</td>\n",
       "      <td>42</td>\n",
       "      <td>147500</td>\n",
       "      <td>47.59</td>\n",
       "      <td>4.72</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>212.13</td>\n",
       "      <td>120.21</td>\n",
       "      <td>47.73</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0</td>\n",
       "      <td>55128.46</td>\n",
       "      <td>66.18</td>\n",
       "      <td>7.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>329</td>\n",
       "      <td>1627.54</td>\n",
       "      <td>1409.43</td>\n",
       "      <td>51</td>\n",
       "      <td>822500</td>\n",
       "      <td>35.00</td>\n",
       "      <td>6.10</td>\n",
       "      <td>4610.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>710.63</td>\n",
       "      <td>451.78</td>\n",
       "      <td>150.85</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0</td>\n",
       "      <td>4530.75</td>\n",
       "      <td>66.25</td>\n",
       "      <td>7.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>3234</td>\n",
       "      <td>1091.56</td>\n",
       "      <td>1357.96</td>\n",
       "      <td>32</td>\n",
       "      <td>8085000</td>\n",
       "      <td>40.08</td>\n",
       "      <td>8.98</td>\n",
       "      <td>25450.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>3095.56</td>\n",
       "      <td>1937.42</td>\n",
       "      <td>773.69</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0</td>\n",
       "      <td>4927.51</td>\n",
       "      <td>66.15</td>\n",
       "      <td>7.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>2339</td>\n",
       "      <td>1537.68</td>\n",
       "      <td>1633.02</td>\n",
       "      <td>45</td>\n",
       "      <td>5847500</td>\n",
       "      <td>38.13</td>\n",
       "      <td>9.29</td>\n",
       "      <td>22110.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>2404.16</td>\n",
       "      <td>1530.38</td>\n",
       "      <td>659.67</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0</td>\n",
       "      <td>4732.04</td>\n",
       "      <td>66.34</td>\n",
       "      <td>7.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>2971</td>\n",
       "      <td>1020.91</td>\n",
       "      <td>630.80</td>\n",
       "      <td>59</td>\n",
       "      <td>7427500</td>\n",
       "      <td>32.76</td>\n",
       "      <td>10.48</td>\n",
       "      <td>17380.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1749.29</td>\n",
       "      <td>1245.07</td>\n",
       "      <td>348.70</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0</td>\n",
       "      <td>25579.34</td>\n",
       "      <td>65.78</td>\n",
       "      <td>7.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>3155</td>\n",
       "      <td>1118.08</td>\n",
       "      <td>469.39</td>\n",
       "      <td>11</td>\n",
       "      <td>7887500</td>\n",
       "      <td>30.41</td>\n",
       "      <td>7.99</td>\n",
       "      <td>15880.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>3059.41</td>\n",
       "      <td>2043.90</td>\n",
       "      <td>477.23</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0</td>\n",
       "      <td>28172.07</td>\n",
       "      <td>65.72</td>\n",
       "      <td>7.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>11475</td>\n",
       "      <td>1249.47</td>\n",
       "      <td>1386.03</td>\n",
       "      <td>41</td>\n",
       "      <td>28687500</td>\n",
       "      <td>38.57</td>\n",
       "      <td>9.50</td>\n",
       "      <td>58790.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>4816.64</td>\n",
       "      <td>3894.10</td>\n",
       "      <td>593.54</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0</td>\n",
       "      <td>5514.48</td>\n",
       "      <td>66.18</td>\n",
       "      <td>7.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>1034</td>\n",
       "      <td>1776.55</td>\n",
       "      <td>1464.70</td>\n",
       "      <td>52</td>\n",
       "      <td>2585000</td>\n",
       "      <td>39.30</td>\n",
       "      <td>14.51</td>\n",
       "      <td>12990.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>1140.18</td>\n",
       "      <td>651.51</td>\n",
       "      <td>300.07</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0</td>\n",
       "      <td>4535.86</td>\n",
       "      <td>66.29</td>\n",
       "      <td>8.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>1035</td>\n",
       "      <td>1304.90</td>\n",
       "      <td>1281.72</td>\n",
       "      <td>68</td>\n",
       "      <td>2587500</td>\n",
       "      <td>35.90</td>\n",
       "      <td>7.51</td>\n",
       "      <td>15420.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>1234.91</td>\n",
       "      <td>632.82</td>\n",
       "      <td>358.06</td>\n",
       "      <td>6.98</td>\n",
       "      <td>0</td>\n",
       "      <td>6165.56</td>\n",
       "      <td>66.14</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>4851</td>\n",
       "      <td>1700.15</td>\n",
       "      <td>1345.04</td>\n",
       "      <td>52</td>\n",
       "      <td>12127500</td>\n",
       "      <td>34.47</td>\n",
       "      <td>7.60</td>\n",
       "      <td>49430.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>2600.48</td>\n",
       "      <td>1983.69</td>\n",
       "      <td>387.60</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0</td>\n",
       "      <td>4236.17</td>\n",
       "      <td>66.23</td>\n",
       "      <td>7.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    f_1    f_2      f_3      f_4  f_5       f_6    f_7    f_8      f_9  f_10   \n",
       "0     1   2558  1506.09   456.63   90   6395000  40.88   7.89  29780.0  0.19  \\\n",
       "1     2  22325    79.11   841.03  180  55812500  51.11   1.21  61900.0  0.02   \n",
       "2     3    115  1449.85   608.43   88    287500  40.42   7.34   3340.0  0.18   \n",
       "3     4   1201  1562.53   295.65   66   3002500  42.40   7.97  18030.0  0.19   \n",
       "4     5    312   950.27   440.86   37    780000  41.43   7.03   3350.0  0.17   \n",
       "5     6     54  1438.13   544.91   82    135000  44.67   6.92   1570.0  0.15   \n",
       "6     7    116  1446.29   580.94   97    290000  41.53   6.24   3660.0  0.15   \n",
       "7     8     57    28.68   715.39  141    142500  51.67   0.83   1810.0  0.02   \n",
       "8     9    188   964.23   456.23   22    470000  38.90   5.89   3720.0  0.15   \n",
       "9    10     64   903.02   274.88   33    160000  41.22   7.90   1850.0  0.19   \n",
       "10   11     59  1127.41  1507.76   42    147500  47.59   4.72   1800.0  0.10   \n",
       "11    1    329  1627.54  1409.43   51    822500  35.00   6.10   4610.0  0.17   \n",
       "12    2   3234  1091.56  1357.96   32   8085000  40.08   8.98  25450.0  0.22   \n",
       "13    3   2339  1537.68  1633.02   45   5847500  38.13   9.29  22110.0  0.24   \n",
       "14    4   2971  1020.91   630.80   59   7427500  32.76  10.48  17380.0  0.32   \n",
       "15    5   3155  1118.08   469.39   11   7887500  30.41   7.99  15880.0  0.26   \n",
       "16    6  11475  1249.47  1386.03   41  28687500  38.57   9.50  58790.0  0.25   \n",
       "17    7   1034  1776.55  1464.70   52   2585000  39.30  14.51  12990.0  0.37   \n",
       "18    8   1035  1304.90  1281.72   68   2587500  35.90   7.51  15420.0  0.21   \n",
       "19    9   4851  1700.15  1345.04   52  12127500  34.47   7.60  49430.0  0.22   \n",
       "\n",
       "    ...      f_42     f_43     f_44   f_45  f_46      f_47   f_48  f_49   \n",
       "0   ...   1000.00   763.16   135.46   3.73     0  33243.19  65.74  7.95  \\\n",
       "1   ...  11500.00  9593.48  1648.80   0.60     0  51572.04  65.73  6.26   \n",
       "2   ...    250.00   150.00    45.13   9.33     1  31692.84  65.81  7.84   \n",
       "3   ...    761.58   453.21   144.97  13.33     1  37696.21  65.67  8.07   \n",
       "4   ...    710.63   512.54   109.16   2.58     0  29038.17  65.66  7.35   \n",
       "5   ...    200.00   150.00    52.22   4.06     0  30967.25  65.77  7.85   \n",
       "6   ...    403.11   164.58   114.82   6.44     0  31258.37  65.79  7.85   \n",
       "7   ...    360.56   165.71   132.47   3.02     0  51985.06  65.67  6.25   \n",
       "8   ...    492.44   256.77   124.72   6.11     0  28871.82  65.67  7.36   \n",
       "9   ...    223.61   182.83    50.12   2.58     0  32053.95  65.58  7.35   \n",
       "10  ...    212.13   120.21    47.73   5.88     0  55128.46  66.18  7.18   \n",
       "11  ...    710.63   451.78   150.85   3.23     0   4530.75  66.25  7.85   \n",
       "12  ...   3095.56  1937.42   773.69   2.21     0   4927.51  66.15  7.24   \n",
       "13  ...   2404.16  1530.38   659.67   2.59     0   4732.04  66.34  7.67   \n",
       "14  ...   1749.29  1245.07   348.70   4.54     0  25579.34  65.78  7.41   \n",
       "15  ...   3059.41  2043.90   477.23   1.70     0  28172.07  65.72  7.58   \n",
       "16  ...   4816.64  3894.10   593.54   1.63     0   5514.48  66.18  7.41   \n",
       "17  ...   1140.18   651.51   300.07   5.80     0   4535.86  66.29  8.01   \n",
       "18  ...   1234.91   632.82   358.06   6.98     0   6165.56  66.14  7.52   \n",
       "19  ...   2600.48  1983.69   387.60   1.60     0   4236.17  66.23  7.96   \n",
       "\n",
       "    target  prediction_value  \n",
       "0        1                 1  \n",
       "1        0                 0  \n",
       "2        1                 1  \n",
       "3        1                 1  \n",
       "4        0                 1  \n",
       "5        1                 1  \n",
       "6        1                 1  \n",
       "7        0                 0  \n",
       "8        1                 1  \n",
       "9        1                 1  \n",
       "10       1                 0  \n",
       "11       0                 0  \n",
       "12       0                 0  \n",
       "13       0                 0  \n",
       "14       1                 1  \n",
       "15       1                 1  \n",
       "16       0                 0  \n",
       "17       0                 0  \n",
       "18       0                 0  \n",
       "19       0                 0  \n",
       "\n",
       "[20 rows x 51 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data['prediction_value']=original_data_pred\n",
    "original_data.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
